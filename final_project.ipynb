{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diazdela/Semantic-Segmentation-of-Breast-Cancer-Tissue/blob/main/final_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1Bv_P9P5l_C"
      },
      "source": [
        "# Final Project - Breast Cancer Semantic Segmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlbJxkxfxYff"
      },
      "source": [
        "## Dataset https://github.com/CancerDataScience/CrowdsourcingDataset-Amgadetal2019.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLyDrp1xYMd6",
        "outputId": "54305148-fde3-45cf-fe36-582c2442c029"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CrowdsourcingDataset-Amgadetal2019'...\n",
            "remote: Enumerating objects: 230, done.\u001b[K\n",
            "remote: Counting objects: 100% (91/91), done.\u001b[K\n",
            "remote: Compressing objects: 100% (83/83), done.\u001b[K\n",
            "remote: Total 230 (delta 47), reused 19 (delta 4), pack-reused 139\u001b[K\n",
            "Receiving objects: 100% (230/230), 74.54 KiB | 1.52 MiB/s, done.\n",
            "Resolving deltas: 100% (107/107), done.\n",
            "/content/CrowdsourcingDataset-Amgadetal2019\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting girder_client\n",
            "  Downloading girder-client-3.1.17.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (8.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.22.4)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.19.3)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (2.25.1)\n",
            "Requirement already satisfied: click>=6.7 in /usr/local/lib/python3.10/dist-packages (from girder_client) (8.1.3)\n",
            "Collecting diskcache (from girder_client)\n",
            "  Downloading diskcache-5.6.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from girder_client) (2.27.1)\n",
            "Collecting requests_toolbelt (from girder_client)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.10.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (23.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.4.2->girder_client) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.4.2->girder_client) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.4.2->girder_client) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.4.2->girder_client) (3.4)\n",
            "Building wheels for collected packages: girder_client\n",
            "  Building wheel for girder_client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for girder_client: filename=girder_client-3.1.17-py3-none-any.whl size=21179 sha256=7304d4d4ee61f7de5fcbdc145b0178d1da490706638fe12592b2b2abf01074b8\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/88/79/eb68de788a8c7a6cf3d101905b31a05dc69aa9ac212f5db922\n",
            "Successfully built girder_client\n",
            "Installing collected packages: diskcache, requests_toolbelt, girder_client\n",
            "Successfully installed diskcache-5.6.1 girder_client-3.1.17 requests_toolbelt-1.0.0\n",
            "STARTED.\n",
            "Downloading RGB image: Slide 1 of 151 (TCGA-A1-A0SK)\n",
            "Downloading mask: Slide 1 of 151 (TCGA-A1-A0SK)\n",
            "Downloading RGB image: Slide 2 of 151 (TCGA-A1-A0SP)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/response.py\", line 444, in _error_catcher\n",
            "    yield\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/response.py\", line 567, in read\n",
            "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/response.py\", line 533, in _fp_read\n",
            "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
            "  File \"/usr/lib/python3.10/http/client.py\", line 466, in read\n",
            "    s = self.fp.read(amt)\n",
            "  File \"/usr/lib/python3.10/socket.py\", line 705, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "  File \"/usr/lib/python3.10/ssl.py\", line 1274, in recv_into\n",
            "    return self.read(nbytes, buffer)\n",
            "  File \"/usr/lib/python3.10/ssl.py\", line 1130, in read\n",
            "    return self._sslobj.read(len, buffer)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/CrowdsourcingDataset-Amgadetal2019/download_crowdsource_dataset.py\", line 212, in <module>\n",
            "    main()\n",
            "  File \"/content/CrowdsourcingDataset-Amgadetal2019/download_crowdsource_dataset.py\", line 194, in main\n",
            "    download_rgbs_and_masks()\n",
            "  File \"/content/CrowdsourcingDataset-Amgadetal2019/download_crowdsource_dataset.py\", line 117, in download_rgbs_and_masks\n",
            "    resp = cf.gc.get(getStr, jsonResp=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/girder_client/__init__.py\", line 471, in get\n",
            "    return self.sendRestRequest('GET', path, parameters, jsonResp=jsonResp)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/girder_client/__init__.py\", line 452, in sendRestRequest\n",
            "    result = f(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/api.py\", line 75, in get\n",
            "    return request('get', url, params=params, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/api.py\", line 61, in request\n",
            "    return session.request(method=method, url=url, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/sessions.py\", line 529, in request\n",
            "    resp = self.send(prep, **send_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/sessions.py\", line 687, in send\n",
            "    r.content\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/models.py\", line 838, in content\n",
            "    self._content = b''.join(self.iter_content(CONTENT_CHUNK_SIZE)) or b''\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/models.py\", line 760, in generate\n",
            "    for chunk in self.raw.stream(chunk_size, decode_content=True):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/response.py\", line 628, in stream\n",
            "    data = self.read(amt=amt, decode_content=decode_content)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/response.py\", line 566, in read\n",
            "    with self._error_catcher():\n",
            "  File \"/usr/lib/python3.10/contextlib.py\", line 153, in __exit__\n",
            "    self.gen.throw(typ, value, traceback)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/response.py\", line 474, in _error_catcher\n",
            "    self._original_response.close()\n",
            "  File \"/usr/lib/python3.10/http/client.py\", line 419, in close\n",
            "    super().close() # set \"closed\" flag\n",
            "  File \"/usr/lib/python3.10/http/client.py\", line 432, in flush\n",
            "    self.fp.flush()\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/CancerDataScience/CrowdsourcingDataset-Amgadetal2019.git\n",
        "%cd CrowdsourcingDataset-Amgadetal2019\n",
        "\n",
        "# Install the required packages\n",
        "!pip install girder_client pillow numpy scikit-image imageio\n",
        "\n",
        "!python download_crowdsource_dataset.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnse40TJ4-z0",
        "outputId": "0c9ce4d2-90ee-4f14-d797-387e018cfa64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['images', 'masks', 'wsis', 'annotations', 'logs', '.git', '__pycache__', 'meta']\n"
          ]
        }
      ],
      "source": [
        "# Identifying Directories\n",
        "import os\n",
        "os.getcwd()\n",
        "\n",
        "# Parent Directory\n",
        "parent_dir = \"/content/CrowdsourcingDataset-Amgadetal2019\"\n",
        "\n",
        "# Sub-directories\n",
        "sub_dirs = [d for d in os.listdir(parent_dir) if os.path.isdir(os.path.join(parent_dir, d))]\n",
        "print(sub_dirs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3-jWbCXl6ZwT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "6c7c8b72-6b7f-46bf-cdd2-73dcda11b5d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['TCGA-A1-A0SK-DX1_xmin45749_ymin25055_MPP-0.2500.png']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-357f83eeba63>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# List files in the sub-directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mimg_file_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_sub_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_sub_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_file_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualize Images\n",
        "img_sub_dir = \"images\"\n",
        "\n",
        "# Path to the sub-directory\n",
        "img_sub_path = os.path.join(parent_dir, img_sub_dir)\n",
        "\n",
        "# List files in sub-directory\n",
        "img_sub_files = os.listdir(img_sub_path)\n",
        "\n",
        "# Print the list of files in the sub-directory\n",
        "print(img_sub_files)\n",
        "\n",
        "# List files in the sub-directory\n",
        "img_file_1 = img_sub_files[1]\n",
        "file_path = os.path.join(img_sub_path, img_file_1)\n",
        "\n",
        "# Visualize\n",
        "image = Image.open(file_path)\n",
        "height=480\n",
        "img_1 = image.resize((int(float(image.size[0])*height/float(image.size[1])),height))\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (5,5)\n",
        "plt.imshow(img_1); plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKTr53ulxRjo"
      },
      "source": [
        "## Model https://github.com/IanTaehoonYoo/semantic-segmentation-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seg-torch"
      ],
      "metadata": {
        "id": "2Kyr2m7wnHAe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee912f69-6158-4f43-8671-fe866c1fca4e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting seg-torch\n",
            "  Downloading seg_torch-0.1.7-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from seg-torch) (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from seg-torch) (0.15.1+cu118)\n",
            "Collecting tensorboardX>=2.0opencv-python (from seg-torch)\n",
            "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from seg-torch) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX>=2.0opencv-python->seg-torch) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX>=2.0opencv-python->seg-torch) (23.1)\n",
            "Requirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorboardX>=2.0opencv-python->seg-torch) (3.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->seg-torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->seg-torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->seg-torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->seg-torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->seg-torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->seg-torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.5.0->seg-torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.5.0->seg-torch) (16.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->seg-torch) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->seg-torch) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.5.0->seg-torch) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->seg-torch) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->seg-torch) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->seg-torch) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->seg-torch) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.5.0->seg-torch) (1.3.0)\n",
            "Installing collected packages: tensorboardX, seg-torch\n",
            "Successfully installed seg-torch-0.1.7 tensorboardX-2.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "from segmentation.data_loader.segmentation_dataset import SegmentationDataset\n",
        "from segmentation.data_loader.transform import Rescale, ToTensor\n",
        "from segmentation.trainer import Trainer\n",
        "from segmentation.predict import *\n",
        "from segmentation.models import all_models\n",
        "from util.logger import Logger\n",
        "\n",
        "train_images = r'/content/CrowdsourcingDataset-Amgadetal2019/images'\n",
        "train_labled = r'/content/CrowdsourcingDataset-Amgadetal2019/masks'\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    model_name = \"fcn8_vgg16\"\n",
        "    device = 'cuda'\n",
        "    batch_size = 4\n",
        "    n_classes = 34\n",
        "    num_epochs = 10\n",
        "    image_axis_minimum_size = 200\n",
        "    pretrained = True\n",
        "    fixed_feature = False\n",
        "    image_target_size = (200, 200)\n",
        "\n",
        "    logger = Logger(model_name=model_name, data_name='example')\n",
        "\n",
        "    ### Loader\n",
        "    compose = transforms.Compose([\n",
        "        transforms.Resize(image_target_size),  # Resize images to a consistent size\n",
        "        ToTensor()\n",
        "         ])\n",
        "\n",
        "    train_datasets = SegmentationDataset(train_images, train_labled, n_classes, compose)\n",
        "    train_loader = torch.utils.data.DataLoader(train_datasets, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "\n",
        "#    test_datasets = SegmentationDataset(test_images, test_labeled, n_classes, compose)\n",
        "#    test_loader = torch.utils.data.DataLoader(test_datasets, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "\n",
        "    ### Model\n",
        "    model = all_models.model_from_name[model_name](n_classes, batch_size,\n",
        "                                                   pretrained=pretrained,\n",
        "                                                   fixed_feature=fixed_feature)\n",
        "    model.to(device)\n",
        "\n",
        "    ###Load model\n",
        "    ###please check the foloder: (.segmentation/test/runs/models)\n",
        "    #logger.load_model(model, 'epoch_15')\n",
        "\n",
        "    ### Optimizers\n",
        "    if pretrained and fixed_feature: #fine tunning\n",
        "        params_to_update = model.parameters()\n",
        "        print(\"Params to learn:\")\n",
        "        params_to_update = []\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad == True:\n",
        "                params_to_update.append(param)\n",
        "                print(\"\\t\", name)\n",
        "        optimizer = torch.optim.Adadelta(params_to_update)\n",
        "    else:\n",
        "        optimizer = torch.optim.Adadelta(model.parameters())\n",
        "\n",
        "\n",
        "    ### Train\n",
        "    #scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "    trainer = Trainer(model, optimizer, logger, num_epochs, train_loader)\n",
        "    trainer.train()\n",
        "\n",
        "\n",
        "    #### Writing the predict result.\n",
        "    predict(model, r'/content/CrowdsourcingDataset-Amgadetal2019/images',\n",
        "             r'/content/CrowdsourcingDataset-Amgadetal2019/masks')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "id": "DpcUBBbonJXy",
        "outputId": "f8379567-347a-4137-b0d1-d25a8de821fc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset verified! \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:   0%|                                             | 0/10 [00:00<?, ?it/s]\n",
            "Train epoch=0: 0it [00:00, ?it/s]\u001b[A\n",
            "Train:  10%|███▋                                 | 1/10 [00:00<00:01,  7.25it/s]\n",
            "Train epoch=1: 0it [00:00, ?it/s]\u001b[A\n",
            "                                 \u001b[A\n",
            "Train epoch=2: 0it [00:00, ?it/s]\u001b[A\n",
            "                                 \u001b[A\n",
            "Train epoch=3: 0it [00:00, ?it/s]\u001b[A\n",
            "                                 \u001b[A\n",
            "Train epoch=4: 0it [00:00, ?it/s]\u001b[A\n",
            "                                 \u001b[A\n",
            "Train epoch=5: 0it [00:00, ?it/s]\u001b[A\n",
            "                                 \u001b[A\n",
            "Train epoch=6: 0it [00:00, ?it/s]\u001b[A\n",
            "                                 \u001b[A\n",
            "Train epoch=7: 0it [00:00, ?it/s]\u001b[A\n",
            "                                 \u001b[A\n",
            "Train epoch=8: 0it [00:00, ?it/s]\u001b[A\n",
            "                                 \u001b[A\n",
            "Train epoch=9: 0it [00:00, ?it/s]\u001b[A\n",
            "Train: 100%|████████████████████████████████████| 10/10 [00:00<00:00, 45.78it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-f9a454542ab5>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m#### Writing the predict result.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     predict(model, r'/content/CrowdsourcingDataset-Amgadetal2019/images',\n\u001b[0m\u001b[1;32m     70\u001b[0m              r'/content/CrowdsourcingDataset-Amgadetal2019/masks')\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/segmentation/predict.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(model, input_path, output_path, colors)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mori_height\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mori_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}