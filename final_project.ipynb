{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diazdela/Semantic-Segmentation-of-Breast-Cancer-Tissue/blob/main/final_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1Bv_P9P5l_C"
      },
      "source": [
        "# Final Project - Breast Cancer Semantic Segmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlbJxkxfxYff"
      },
      "source": [
        "## Dataset https://github.com/CancerDataScience/CrowdsourcingDataset-Amgadetal2019.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLyDrp1xYMd6"
      },
      "outputs": [],
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/CancerDataScience/CrowdsourcingDataset-Amgadetal2019.git\n",
        "%cd CrowdsourcingDataset-Amgadetal2019\n",
        "\n",
        "# Install the required packages\n",
        "!pip install girder_client pillow numpy scikit-image imageio\n",
        "\n",
        "!python download_crowdsource_dataset.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnse40TJ4-z0"
      },
      "outputs": [],
      "source": [
        "# Identifying Directories\n",
        "import os\n",
        "os.getcwd()\n",
        "\n",
        "# Parent Directory\n",
        "parent_dir = \"/content/CrowdsourcingDataset-Amgadetal2019\"\n",
        "\n",
        "# Sub-directories\n",
        "sub_dirs = [d for d in os.listdir(parent_dir) if os.path.isdir(os.path.join(parent_dir, d))]\n",
        "print(sub_dirs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-jWbCXl6ZwT"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualize Images\n",
        "img_sub_dir = \"images\"\n",
        "\n",
        "# Path to the sub-directory\n",
        "img_sub_path = os.path.join(parent_dir, img_sub_dir)\n",
        "\n",
        "# List files in sub-directory\n",
        "img_sub_files = os.listdir(img_sub_path)\n",
        "\n",
        "# Print the list of files in the sub-directory\n",
        "print(img_sub_files)\n",
        "\n",
        "# List files in the sub-directory\n",
        "img_file_1 = img_sub_files[1]\n",
        "file_path = os.path.join(img_sub_path, img_file_1)\n",
        "\n",
        "# Visualize\n",
        "image = Image.open(file_path)\n",
        "height=480\n",
        "img_1 = image.resize((int(float(image.size[0])*height/float(image.size[1])),height))\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (5,5)\n",
        "plt.imshow(img_1); plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKTr53ulxRjo"
      },
      "source": [
        "## Model https://github.com/IanTaehoonYoo/semantic-segmentation-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seg-torch"
      ],
      "metadata": {
        "id": "2Kyr2m7wnHAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "from segmentation.data_loader.segmentation_dataset import SegmentationDataset\n",
        "from segmentation.data_loader.transform import Rescale, ToTensor\n",
        "from segmentation.trainer import Trainer\n",
        "from segmentation.predict import *\n",
        "from segmentation.models import all_models\n",
        "from util.logger import Logger\n",
        "\n",
        "train_images = r'/content/CrowdsourcingDataset-Amgadetal2019/images'\n",
        "train_labled = r'/content/CrowdsourcingDataset-Amgadetal2019/masks'\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    model_name = \"fcn8_vgg16\"\n",
        "    device = 'cuda'\n",
        "    batch_size = 4\n",
        "    n_classes = 34\n",
        "    num_epochs = 10\n",
        "    image_axis_minimum_size = 200\n",
        "    pretrained = True\n",
        "    fixed_feature = False\n",
        "    image_target_size = (200, 200)\n",
        "\n",
        "    logger = Logger(model_name=model_name, data_name='example')\n",
        "\n",
        "    ### Loader\n",
        "    compose = transforms.Compose([\n",
        "        transforms.Resize(image_target_size),  # Resize images to a consistent size\n",
        "        ToTensor()\n",
        "         ])\n",
        "\n",
        "    train_datasets = SegmentationDataset(train_images, train_labled, n_classes, compose)\n",
        "    train_loader = torch.utils.data.DataLoader(train_datasets, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "\n",
        "#    test_datasets = SegmentationDataset(test_images, test_labeled, n_classes, compose)\n",
        "#    test_loader = torch.utils.data.DataLoader(test_datasets, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "\n",
        "    ### Model\n",
        "    model = all_models.model_from_name[model_name](n_classes, batch_size,\n",
        "                                                   pretrained=pretrained,\n",
        "                                                   fixed_feature=fixed_feature)\n",
        "    model.to(device)\n",
        "\n",
        "    ###Load model\n",
        "    ###please check the foloder: (.segmentation/test/runs/models)\n",
        "    #logger.load_model(model, 'epoch_15')\n",
        "\n",
        "    ### Optimizers\n",
        "    if pretrained and fixed_feature: #fine tunning\n",
        "        params_to_update = model.parameters()\n",
        "        print(\"Params to learn:\")\n",
        "        params_to_update = []\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad == True:\n",
        "                params_to_update.append(param)\n",
        "                print(\"\\t\", name)\n",
        "        optimizer = torch.optim.Adadelta(params_to_update)\n",
        "    else:\n",
        "        optimizer = torch.optim.Adadelta(model.parameters())\n",
        "\n",
        "\n",
        "    ### Train\n",
        "    #scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "    trainer = Trainer(model, optimizer, logger, num_epochs, train_loader)\n",
        "    trainer.train()\n",
        "\n"
      ],
      "metadata": {
        "id": "DpcUBBbonJXy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}